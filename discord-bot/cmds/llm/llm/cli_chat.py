import re

from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA


# Step 1: è¼‰å…¥äº‹å…ˆå»ºç«‹å¥½çš„ FAISS Index
print("ğŸ”„ è¼‰å…¥ RAG è³‡æ–™åº«...")

embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
db = FAISS.load_local(
    "/discord-bot/cmds/llm/database/vlrt_pro_settings",
    embedding,
    allow_dangerous_deserialization=True
)
retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 5})


# Step 2: è¨­å®š Prompt + LLM
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
ä½ æ˜¯å°ˆæ¥­çš„é›»å­ç«¶æŠ€éšŠä¼è³‡æ–™åŠ©ç†ï¼Œæ ¹æ“šè³‡æ–™åº«ä¸­çš„è³‡è¨Šå›ç­”å•é¡Œã€‚
è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”æ‰€æœ‰å•é¡Œï¼Œä¸¦ç†è§£å•é¡Œä¸­æ‰€æœ‰ç”¨è©ç‚ºç¹é«”èªå¢ƒã€‚

è«‹åš´æ ¼éµå®ˆä»¥ä¸‹è¦æ±‚ï¼š
1. åƒ…å›è¦†å•é¡Œçš„ç›´æ¥ç­”æ¡ˆï¼Œç¦æ­¢è¼¸å‡ºä»»ä½•ã€Œæ€è€ƒã€ã€ã€Œæ¨ç†ã€ã€ã€Œåˆ†æã€æ–‡å­—ï¼Œä¸è¦å‡ºç¾ <think> æ¨™ç±¤æˆ–é¡ä¼¼å…§å®¹ã€‚
2. å›ç­”è¦ç°¡æ½”æ˜ç¢ºï¼Œè‹¥è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ï¼Œè«‹ç›´æ¥å›è¦†ã€Œè³‡æ–™åº«ä¸­ç„¡ç›¸é—œè³‡è¨Šã€ã€‚
3. è‹¥å•é¡Œæ¶‰åŠéšŠä¼æˆå“¡ï¼Œè«‹åªåˆ—å‡ºè©²éšŠä¼æ‰€æœ‰é¸æ‰‹åå­—ï¼Œä¸å¤šé¤˜è§£é‡‹ã€‚
4. è‹¥å•é¡Œæ¶‰åŠæŸä½é¸æ‰‹çš„è¨­å‚™é…å‚™ï¼Œè«‹ç”¨æ¢åˆ—æ–¹å¼åˆ—å‡ºé—œéµé…å‚™è³‡è¨Šã€‚

ç¯„ä¾‹ï¼š
ç”¨æˆ¶å•:ã€Œteam 100 Thieves æœ‰å“ªäº›æˆå“¡ï¼Ÿã€
åŠ©ç†ç­”:ã€Œ100 Thieves æˆå“¡: Boostio, Nadeshot, Zander, Cryocells, Asuna, eeiuã€

ç”¨æˆ¶å•ï¼š{question}

ä»¥ä¸‹æ˜¯ä¾†è‡ªè³‡æ–™åº«çš„å…§å®¹ï¼š
{context}

ç­”è¦†ï¼š
"""
)

llm = OllamaLLM(model="llama3:8b")

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": prompt}
)


# Step 3: CLI å°è©±
print("ğŸ¤– å•Ÿå‹• CLI RAG å°è©±æ¨¡å¼ã€‚è¼¸å…¥å•é¡Œé–‹å§‹å°è©±ï¼Œè¼¸å…¥ /bye çµæŸã€‚\n")

while True:
    user_input = input("ä½ ï¼š")
    if user_input.strip().lower() == "/bye":
        print("ğŸ¤–ï¼šå†è¦‹ï¼Œç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼")
        break
    try:
        response = qa_chain.invoke({"query": user_input})
        answer = response.get("result") or response.get("answer") or str(response)
        print(f"ğŸ¤–ï¼š{answer}\n")
    except Exception as e:
        print(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\n")